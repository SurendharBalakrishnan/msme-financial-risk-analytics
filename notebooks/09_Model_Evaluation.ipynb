{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76ae1dfb-5b7e-4bbd-bf83-8c6819a08774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6db13ea1-86e7-4071-aa6e-85dfdbff3bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "df = spark.table('msme_risk_analytics.gold_ml_training_data')\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "feature_cols = ['loan_amount', 'income', 'Credit_Score', 'LTV', 'dtir1', \n",
    "                'loan_to_income_ratio', 'risk_score']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "train_vec = assembler.transform(train)\n",
    "test_vec = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f98c3d4f-d82c-4c6f-ba1b-9a5d64731895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##  Train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0d0f3b9-66c4-444e-b270-96918a78ef05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(featuresCol='features', labelCol='Status', maxIter=20, seed=42)\n",
    "gbt_model = gbt.fit(train_vec)\n",
    "predictions = gbt_model.transform(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ff254ce-2e70-4506-b5a1-6e4aab64ec75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b72bcf7-90a5-454b-b3b8-1d840f8cd31b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----+\n|Status|prediction|count|\n+------+----------+-----+\n|     0|       1.0|   39|\n|     0|       0.0| 2133|\n|     1|       1.0|  173|\n|     1|       0.0|  684|\n+------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('Status', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3b67828-224c-4e9e-9399-2dbce9aa16b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b591c5ac-e031-47e4-bafc-c9cc1fc86478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature  importance\n3                   LTV    0.255088\n5  loan_to_income_ratio    0.192788\n4                 dtir1    0.173469\n0           loan_amount    0.145198\n1                income    0.102258\n2          Credit_Score    0.075848\n6            risk_score    0.055350\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': gbt_model.featureImportances.toArray()\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79708377-b39f-4530-b679-875740949612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26ebb120-0ff0-45f3-9baa-4b38decc7159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DAY 3 COMPLETE - Model trained & evaluated\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame([{\n",
    "    'model': 'GBT',\n",
    "    'roc_auc': 0.6955,\n",
    "    'accuracy': 0.7613,\n",
    "    'precision': 684/(684+39),\n",
    "    'recall': 684/(684+173),\n",
    "    'train_records': train.count(),\n",
    "    'test_records': test.count()\n",
    "}]).write.format('delta').mode('overwrite') \\\n",
    "  .saveAsTable('msme_risk_analytics.gold_best_model_metrics')\n",
    "\n",
    "print(\"✅ DAY 3 COMPLETE - Model trained & evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b287ecdb-40be-4294-8f5d-3f6ea8fa1a8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8917257583684502>, line 6\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Loan Prediction\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m new_loan \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame([{\n",
       "\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloan_amount\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m250000\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mincome\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m5000\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCredit_Score\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m650\u001B[39m,\n",
       "\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLTV\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m85\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdtir1\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m45\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloan_to_income_ratio\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m50\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrisk_score\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m55\u001B[39m\n",
       "\u001B[1;32m      5\u001B[0m }])\n",
       "\u001B[0;32m----> 6\u001B[0m new_vec \u001B[38;5;241m=\u001B[39m assembler\u001B[38;5;241m.\u001B[39mtransform(new_loan)\n",
       "\u001B[1;32m      7\u001B[0m prediction \u001B[38;5;241m=\u001B[39m gbt_model\u001B[38;5;241m.\u001B[39mtransform(new_vec)\n",
       "\u001B[1;32m      8\u001B[0m prediction\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprediction\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprobability\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'assembler' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'assembler' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'assembler' is not defined\n[Trace ID: 00-70ee96c380c839ba565e21cca90724e3-d399160861b5a633-00]"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KAN00",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8917257583684502>, line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Loan Prediction\u001B[39;00m\n\u001B[1;32m      2\u001B[0m new_loan \u001B[38;5;241m=\u001B[39m spark\u001B[38;5;241m.\u001B[39mcreateDataFrame([{\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloan_amount\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m250000\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mincome\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m5000\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCredit_Score\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m650\u001B[39m,\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLTV\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m85\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdtir1\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m45\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloan_to_income_ratio\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m50\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrisk_score\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m55\u001B[39m\n\u001B[1;32m      5\u001B[0m }])\n\u001B[0;32m----> 6\u001B[0m new_vec \u001B[38;5;241m=\u001B[39m assembler\u001B[38;5;241m.\u001B[39mtransform(new_loan)\n\u001B[1;32m      7\u001B[0m prediction \u001B[38;5;241m=\u001B[39m gbt_model\u001B[38;5;241m.\u001B[39mtransform(new_vec)\n\u001B[1;32m      8\u001B[0m prediction\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprediction\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprobability\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
        "\u001B[0;31mNameError\u001B[0m: name 'assembler' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loan Prediction\n",
    "new_loan = spark.createDataFrame([{\n",
    "    'loan_amount': 250000, 'income': 5000, 'Credit_Score': 650,\n",
    "    'LTV': 85, 'dtir1': 45, 'loan_to_income_ratio': 50, 'risk_score': 55\n",
    "}])\n",
    "new_vec = assembler.transform(new_loan)\n",
    "prediction = gbt_model.transform(new_vec)\n",
    "prediction.select('prediction', 'probability').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c41fc5fe-e0ba-4915-ae7d-6eab1487a6a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09_Model_Evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}